{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNRUSw9xGu/EmGWobvxHWJ7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mansi05041/Mask_detection/blob/main/Face_Mask_Detection.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNGrjw88dDGb"
      },
      "source": [
        "## project:Face Mask detector for Covid-19"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iycz0ybSejI4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "07cbdb92-2707-4c74-fb92-cef8f2d62e44"
      },
      "source": [
        "## import the libraries for building CNN\n",
        "import keras\n",
        "import PIL"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50lNsHZdgRak"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense,Dropout\n",
        "from keras.layers import Flatten"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uFpw2_g0gyMk"
      },
      "source": [
        "## intialling the CNN\n",
        "classifier=Sequential()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oUH5qE32g-4g"
      },
      "source": [
        "## convolution\n",
        "classifier.add(Conv2D(32,(3,3),input_shape=(64,64,3),activation='relu'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsHA6mpHhfnn"
      },
      "source": [
        "## pooling \n",
        "classifier.add(MaxPooling2D(pool_size=(2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdeMUsiGihlL"
      },
      "source": [
        "## adding another convolutional layer to imoprove the accuracy\n",
        "classifier.add(Conv2D(32, (3, 3), activation='relu'))\n",
        "classifier.add(MaxPooling2D(pool_size= (2,2)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4dUhAmzoihlP"
      },
      "source": [
        "## flattening\n",
        "classifier.add(Flatten())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Et-42OFMkKAx"
      },
      "source": [
        "## full connection\n",
        "classifier.add(Dense(units=128,activation='relu'))\n",
        "classifier.add(Dropout(0.1))\n",
        "classifier.add(Dense(units=64,activation='relu'))\n",
        "classifier.add(Dropout(0.1))\n",
        "classifier.add(Dense(units=1,activation='sigmoid'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DT5L0E28legd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "2dc44073-4907-44d1-eaf1-9a3d2807fcc6"
      },
      "source": [
        "classifier.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_1 (Conv2D)            (None, 62, 62, 32)        896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 31, 31, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 29, 29, 32)        9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 14, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 6272)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 128)               802944    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 64)                8256      \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 821,409\n",
            "Trainable params: 821,409\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZEmz9JpVllUh"
      },
      "source": [
        "## compiling \n",
        "classifier.compile(optimizer='adam',loss='binary_crossentropy',metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HA8Zlb5Il7Bw"
      },
      "source": [
        "## fit CNN to images\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "INHwfvnKmald"
      },
      "source": [
        "t1=ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2,horizontal_flip=True)\n",
        "t2=ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T2deyZJzm0iX",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "66ced325-7c50-4079-dac3-95b09b6e7efc"
      },
      "source": [
        "## importing data \n",
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54gthZePnY2t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e64aeab7-d8e9-4216-f1ae-35c734c9dc3f"
      },
      "source": [
        "training_set=t1.flow_from_directory('/content/gdrive/My Drive/dataset/covid  mask  project/train',\n",
        "                                    target_size=(64,64),batch_size=32,class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1134 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0tr1pH4n--e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c49f8d06-a9a4-4a64-f088-07e4eb347972"
      },
      "source": [
        "test_set=t2.flow_from_directory('/content/gdrive/My Drive/dataset/covid  mask  project/test',\n",
        "                                target_size=(64,64),batch_size=32,class_mode='binary')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 198 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N97f-PgyqO77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "outputId": "6d23cd7e-597b-4351-eb68-cd162d9d45ca"
      },
      "source": [
        "classifier.fit_generator(training_set,steps_per_epoch=1134/32,epochs=26,\n",
        "                         validation_data=test_set,validation_steps=198/32)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/26\n",
            "36/35 [==============================] - 177s 5s/step - loss: 0.5267 - accuracy: 0.7178 - val_loss: 0.1950 - val_accuracy: 0.5909\n",
            "Epoch 2/26\n",
            "36/35 [==============================] - 12s 346ms/step - loss: 0.2385 - accuracy: 0.9189 - val_loss: 0.0784 - val_accuracy: 0.7121\n",
            "Epoch 3/26\n",
            "36/35 [==============================] - 12s 343ms/step - loss: 0.1356 - accuracy: 0.9515 - val_loss: 0.8987 - val_accuracy: 0.7222\n",
            "Epoch 4/26\n",
            "36/35 [==============================] - 12s 337ms/step - loss: 0.0930 - accuracy: 0.9674 - val_loss: 0.4700 - val_accuracy: 0.7424\n",
            "Epoch 5/26\n",
            "36/35 [==============================] - 12s 343ms/step - loss: 0.0827 - accuracy: 0.9709 - val_loss: 1.7306 - val_accuracy: 0.7222\n",
            "Epoch 6/26\n",
            "36/35 [==============================] - 12s 340ms/step - loss: 0.0610 - accuracy: 0.9744 - val_loss: 1.7362 - val_accuracy: 0.7071\n",
            "Epoch 7/26\n",
            "36/35 [==============================] - 12s 341ms/step - loss: 0.0636 - accuracy: 0.9744 - val_loss: 0.0342 - val_accuracy: 0.7374\n",
            "Epoch 8/26\n",
            "36/35 [==============================] - 12s 345ms/step - loss: 0.0618 - accuracy: 0.9762 - val_loss: 0.1900 - val_accuracy: 0.7121\n",
            "Epoch 9/26\n",
            "36/35 [==============================] - 12s 342ms/step - loss: 0.0511 - accuracy: 0.9815 - val_loss: 0.6664 - val_accuracy: 0.7222\n",
            "Epoch 10/26\n",
            "36/35 [==============================] - 12s 342ms/step - loss: 0.0406 - accuracy: 0.9850 - val_loss: 0.8365 - val_accuracy: 0.7424\n",
            "Epoch 11/26\n",
            "36/35 [==============================] - 12s 344ms/step - loss: 0.0464 - accuracy: 0.9771 - val_loss: 1.1888 - val_accuracy: 0.7424\n",
            "Epoch 12/26\n",
            "36/35 [==============================] - 13s 348ms/step - loss: 0.0469 - accuracy: 0.9824 - val_loss: 1.7553 - val_accuracy: 0.6919\n",
            "Epoch 13/26\n",
            "36/35 [==============================] - 12s 338ms/step - loss: 0.0429 - accuracy: 0.9868 - val_loss: 0.1602 - val_accuracy: 0.7222\n",
            "Epoch 14/26\n",
            "36/35 [==============================] - 12s 338ms/step - loss: 0.0228 - accuracy: 0.9921 - val_loss: 0.8185 - val_accuracy: 0.6263\n",
            "Epoch 15/26\n",
            "36/35 [==============================] - 12s 339ms/step - loss: 0.0308 - accuracy: 0.9868 - val_loss: 0.1248 - val_accuracy: 0.7475\n",
            "Epoch 16/26\n",
            "36/35 [==============================] - 12s 345ms/step - loss: 0.0420 - accuracy: 0.9859 - val_loss: 1.3733 - val_accuracy: 0.7273\n",
            "Epoch 17/26\n",
            "36/35 [==============================] - 12s 346ms/step - loss: 0.0169 - accuracy: 0.9938 - val_loss: 0.1823 - val_accuracy: 0.7020\n",
            "Epoch 18/26\n",
            "36/35 [==============================] - 13s 351ms/step - loss: 0.0173 - accuracy: 0.9947 - val_loss: 2.0056 - val_accuracy: 0.6970\n",
            "Epoch 19/26\n",
            "36/35 [==============================] - 12s 345ms/step - loss: 0.0278 - accuracy: 0.9894 - val_loss: 2.8205 - val_accuracy: 0.6768\n",
            "Epoch 20/26\n",
            "36/35 [==============================] - 12s 338ms/step - loss: 0.0334 - accuracy: 0.9868 - val_loss: 1.7786 - val_accuracy: 0.6970\n",
            "Epoch 21/26\n",
            "36/35 [==============================] - 12s 341ms/step - loss: 0.0092 - accuracy: 0.9965 - val_loss: 0.6657 - val_accuracy: 0.6768\n",
            "Epoch 22/26\n",
            "36/35 [==============================] - 13s 349ms/step - loss: 0.0276 - accuracy: 0.9877 - val_loss: 1.4015 - val_accuracy: 0.6818\n",
            "Epoch 23/26\n",
            "36/35 [==============================] - 12s 338ms/step - loss: 0.0420 - accuracy: 0.9868 - val_loss: 0.4937 - val_accuracy: 0.7121\n",
            "Epoch 24/26\n",
            "36/35 [==============================] - 12s 338ms/step - loss: 0.0276 - accuracy: 0.9868 - val_loss: 0.4605 - val_accuracy: 0.6313\n",
            "Epoch 25/26\n",
            "36/35 [==============================] - 13s 359ms/step - loss: 0.0092 - accuracy: 0.9982 - val_loss: 1.3785 - val_accuracy: 0.7121\n",
            "Epoch 26/26\n",
            "36/35 [==============================] - 12s 341ms/step - loss: 0.0072 - accuracy: 0.9965 - val_loss: 0.1182 - val_accuracy: 0.6818\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7fc398c298d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ts0j_Ub0FOB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d9c64cbe-9057-4d63-a887-a0b029aa86ca"
      },
      "source": [
        "# predictions for people wearing mask  image using train model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "tested_image = image.load_img('/content/gdrive/My Drive/dataset/covid  mask  project/mask_or_without-mask2.jpg',\n",
        "                              target_size=(64,64))\n",
        "tested_image = image.img_to_array(tested_image)\n",
        "tested_image = np.expand_dims(tested_image,axis = 0)\n",
        "output = classifier.predict(tested_image)\n",
        "training_set.class_indices\n",
        "if output[0][0] ==1:\n",
        "  prediction = 'not wearing mask'\n",
        "  print(prediction)\n",
        "else:\n",
        "  prediction = 'wearing mask'\n",
        "  print(prediction)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "wearing mask\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p0yXGvo7ZbVl",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4527d5be-48c2-4111-c92f-949bc805c9f7"
      },
      "source": [
        "# predictions for people not wearing mask image using train model\n",
        "tested_image = image.load_img('/content/gdrive/My Drive/dataset/covid  mask  project/mask_or_without-mask1.jpg',\n",
        "                              target_size=(64,64))\n",
        "tested_image = image.img_to_array(tested_image)\n",
        "tested_image = np.expand_dims(tested_image,axis = 0)\n",
        "output = classifier.predict(tested_image)\n",
        "training_set.class_indices\n",
        "if output[0][0] ==1:\n",
        "  prediction = 'not wearing mask'\n",
        "  print(prediction )\n",
        "else:\n",
        "  prediction = 'wearing mask'\n",
        "  print(prediction )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "not wearing mask\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}